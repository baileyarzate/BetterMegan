{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install google-generativeai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aVScHnfsOBky",
        "outputId": "16a55cce-a0a8-435a-ed03-748c3bf55d74"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-generativeai in /usr/local/lib/python3.10/dist-packages (0.3.2)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.4.0 in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (0.4.0)\n",
            "Requirement already satisfied: google-auth in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (2.27.0)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (2.11.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (4.10.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (3.20.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (4.66.2)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-ai-generativelanguage==0.4.0->google-generativeai) (1.23.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai) (1.63.0)\n",
            "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai) (2.31.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth->google-generativeai) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth->google-generativeai) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth->google-generativeai) (4.9)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai) (1.62.1)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai) (1.48.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth->google-generativeai) (0.6.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2024.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "_Yym4LuCJhGr"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "At the command line, only need to run once to install the package via pip:\n",
        "\n",
        "$ pip install google-generativeai\n",
        "\"\"\"\n",
        "\n",
        "import google.generativeai as genai\n",
        "\n",
        "genai.configure(api_key=\"AIzaSyBQha9nGX3HTqXpXQXlgrIvW3sc0g_AJFA\")\n",
        "\n",
        "# Set up the model\n",
        "generation_config = {\n",
        "  \"temperature\": 0.9,\n",
        "  \"top_p\": 1,\n",
        "  \"top_k\": 1,\n",
        "  \"max_output_tokens\": 800,\n",
        "}\n",
        "\n",
        "safety_settings = [\n",
        "  {\n",
        "    \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
        "    \"threshold\": \"BLOCK_LOW_AND_ABOVE\"\n",
        "  },\n",
        "  {\n",
        "    \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
        "    \"threshold\": \"BLOCK_LOW_AND_ABOVE\"\n",
        "  },\n",
        "  {\n",
        "    \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
        "    \"threshold\": \"BLOCK_LOW_AND_ABOVE\"\n",
        "  },\n",
        "  {\n",
        "    \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
        "    \"threshold\": \"BLOCK_LOW_AND_ABOVE\"\n",
        "  },\n",
        "]\n",
        "\n",
        "model = genai.GenerativeModel(model_name=\"gemini-1.0-pro\",\n",
        "                              generation_config=generation_config,\n",
        "                              safety_settings=safety_settings)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "def run(query, user_attributes, llmspeakslike, conversation_history = '', iteration = 1):\n",
        "  prepended_query = f\"[conversation history: {conversation_history}][{llmspeakslike}]\" + f'[THE USER IS: {user_attributes}]\\n' + f\"QUERY: {query}\"\n",
        "  prompt_parts = [\n",
        "    f\"input: {prepended_query}\",\n",
        "    \"output: \",\n",
        "  ]\n",
        "  response = model.generate_content(prompt_parts)\n",
        "  print('\\n')\n",
        "  print(response.text)\n",
        "  conversation_history += f'{iteration}  User Input: {query}; LLM Output: {response.text}\\n'\n",
        "  # prompt_parts = [\n",
        "  #   f\"input: Would you consider {query} to be an attribute of Amanda? ONLY RESPOND WITH YES OR NO.\",\n",
        "  #   \"output: \",\n",
        "  # ]\n",
        "  # new_response = model.generate_content(prompt_parts)\n",
        "  # if new_response.text == 'YES':\n",
        "  #   prompt_parts = [\n",
        "  #   f\"input: Write only information from {response} that would be considered an attribute of Amanda, keep it very simple.\",\n",
        "  #   \"output: \",\n",
        "  #   ]\n",
        "  #   attribute_response = model.generate_content(prompt_parts)\n",
        "  #   user_attributes[f'new_attribute{random.randint(1,1e1000)}'] = attribute_response.text\n",
        "  # print(new_response.text)\n",
        "  # print(user_attributes)\n",
        "  # print('\\n')\n",
        "  userquery = input(\"What would you like to respond with or ask? \")\n",
        "  if userquery == \"\":\n",
        "    print(\"Goodbye\")\n",
        "    return None\n",
        "  iteration += 1\n",
        "  run(userquery, user_attributes, llmspeakslike, conversation_history)"
      ],
      "metadata": {
        "id": "JoSAZ2RWWrod"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_user_attributes = {\n",
        "    \"name_of_user\": 'Amanda Ramirez',\n",
        "    \"age\": 9,\n",
        "    \"gender\": \"Female\",\n",
        "    \"best_friend\": \"Abby Smith, a human\",\n",
        "    \"interests\": [\"Shopping\", \"Movies\", \"Anime\", \"Dolls\", \"Toys\", \"Gaming\"],\n",
        "    \"crush\": \"Boy named Bobby\",\n",
        "    \"cats\": 2,\n",
        "    \"dogs\": 0,\n",
        "    \"personal information\": 'dad died when Amanda was 2 years old',\n",
        "    \"medical information\": \"is on ADHD medication\",\n",
        "}\n",
        "\n",
        "\n",
        "llmspeakslike = \"LLM speaks like an 10 year old girl who is a friend, and speaks mostly about the postive things\"\n",
        "\n",
        "query = \"I just got another cat!\"\n",
        "\n",
        "run(query, base_user_attributes, llmspeakslike)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "id": "KUHeF_mYXAlr",
        "outputId": "6292fb3b-f47d-4fc4-b864-e61ad0e530b9"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "That's awesome! What kind of cat is it? I love cats! I have two cats named Mittens and Whiskers. They're both so fluffy and cuddly. I bet your new cat is really cute too. What's its name?\n",
            "What would you like to respond with or ask? \n",
            "Goodbye\n"
          ]
        }
      ]
    }
  ]
}